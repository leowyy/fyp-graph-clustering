{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/signapoop/Desktop/fyp-graph-clustering'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from time import time\n",
    "import lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.plot_embedding import plot_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# we only want to keep the body of the documents!\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "\n",
    "# fetch train and test data\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=remove)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n",
      "7532\n"
     ]
    }
   ],
   "source": [
    "print(len(newsgroups_train.target))\n",
    "print(len(newsgroups_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of cleaned news in string format\n",
    "# only keep letters & make them all lower case\n",
    "news = [' '.join(filter(str.isalpha, raw.lower().split())) for raw in newsgroups_train.data]\n",
    "labels = list(newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 11314\n",
      "INFO:lda:vocab_size: 12176\n",
      "INFO:lda:n_words: 616447\n",
      "INFO:lda:n_topics: 20\n",
      "INFO:lda:n_iter: 500\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "/Users/signapoop/anaconda3/envs/py36/lib/python3.6/site-packages/lda/utils.py:55: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if sparse and not np.issubdtype(doc_word.dtype, int):\n",
      "INFO:lda:<0> log likelihood: -7817484\n",
      "INFO:lda:<10> log likelihood: -5777165\n",
      "INFO:lda:<20> log likelihood: -5522489\n",
      "INFO:lda:<30> log likelihood: -5423408\n",
      "INFO:lda:<40> log likelihood: -5370560\n",
      "INFO:lda:<50> log likelihood: -5339491\n",
      "INFO:lda:<60> log likelihood: -5317378\n",
      "INFO:lda:<70> log likelihood: -5300659\n",
      "INFO:lda:<80> log likelihood: -5289006\n",
      "INFO:lda:<90> log likelihood: -5278211\n",
      "INFO:lda:<100> log likelihood: -5270574\n",
      "INFO:lda:<110> log likelihood: -5264278\n",
      "INFO:lda:<120> log likelihood: -5259601\n",
      "INFO:lda:<130> log likelihood: -5256433\n",
      "INFO:lda:<140> log likelihood: -5253385\n",
      "INFO:lda:<150> log likelihood: -5248674\n",
      "INFO:lda:<160> log likelihood: -5247226\n",
      "INFO:lda:<170> log likelihood: -5246047\n",
      "INFO:lda:<180> log likelihood: -5243154\n",
      "INFO:lda:<190> log likelihood: -5241173\n",
      "INFO:lda:<200> log likelihood: -5240298\n",
      "INFO:lda:<210> log likelihood: -5238384\n",
      "INFO:lda:<220> log likelihood: -5236131\n",
      "INFO:lda:<230> log likelihood: -5235111\n",
      "INFO:lda:<240> log likelihood: -5234926\n",
      "INFO:lda:<250> log likelihood: -5232398\n",
      "INFO:lda:<260> log likelihood: -5230275\n",
      "INFO:lda:<270> log likelihood: -5230970\n",
      "INFO:lda:<280> log likelihood: -5231375\n",
      "INFO:lda:<290> log likelihood: -5229353\n",
      "INFO:lda:<300> log likelihood: -5227419\n",
      "INFO:lda:<310> log likelihood: -5227592\n",
      "INFO:lda:<320> log likelihood: -5225995\n",
      "INFO:lda:<330> log likelihood: -5225403\n",
      "INFO:lda:<340> log likelihood: -5223504\n",
      "INFO:lda:<350> log likelihood: -5220989\n",
      "INFO:lda:<360> log likelihood: -5220953\n",
      "INFO:lda:<370> log likelihood: -5220301\n",
      "INFO:lda:<380> log likelihood: -5218119\n",
      "INFO:lda:<390> log likelihood: -5216438\n",
      "INFO:lda:<400> log likelihood: -5216408\n",
      "INFO:lda:<410> log likelihood: -5216392\n",
      "INFO:lda:<420> log likelihood: -5214596\n",
      "INFO:lda:<430> log likelihood: -5214724\n",
      "INFO:lda:<440> log likelihood: -5213597\n",
      "INFO:lda:<450> log likelihood: -5212667\n",
      "INFO:lda:<460> log likelihood: -5212446\n",
      "INFO:lda:<470> log likelihood: -5213513\n",
      "INFO:lda:<480> log likelihood: -5212546\n",
      "INFO:lda:<490> log likelihood: -5211264\n",
      "INFO:lda:<499> log likelihood: -5213142\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "n_topics = 20 # number of topics\n",
    "n_iter = 500 # number of iterations\n",
    "\n",
    "# vectorizer: ignore English stopwords & words that occur less than 5 times\n",
    "cvectorizer = CountVectorizer(min_df=5, stop_words='english')\n",
    "cvz = cvectorizer.fit_transform(news)\n",
    "\n",
    "# train an LDA model\n",
    "lda_model = lda.LDA(n_topics=n_topics, n_iter=n_iter)\n",
    "X_topics = lda_model.fit_transform(cvz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 20)\n",
      "11314\n"
     ]
    }
   ],
   "source": [
    "print(X_topics.shape)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "_idx = np.amax(X_topics, axis=1) > threshold  # idx of doc that above the threshold\n",
    "X_topics = X_topics[_idx]\n",
    "labels = [l for i,l in enumerate(labels) if _idx[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first 200 characters of each news article\n",
    "news_snippets = [n[:200] for i,n in enumerate(news) if _idx[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [newsgroups_train.target_names[l] for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4101, 20)\n",
      "4101\n",
      "4101\n"
     ]
    }
   ],
   "source": [
    "print(X_topics.shape)\n",
    "print(len(labels))\n",
    "print(len(news_snippets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 4101 samples in 0.004s...\n",
      "[t-SNE] Computed neighbors for 4101 samples in 0.664s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 4101\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 4101\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 4101\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 4101\n",
      "[t-SNE] Computed conditional probabilities for sample 4101 / 4101\n",
      "[t-SNE] Mean sigma: 0.077350\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 61.185852\n",
      "[t-SNE] Error after 1000 iterations: 0.793792\n",
      "sklearn took 67.00283527374268 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn import manifold\n",
    "tsne_model = manifold.TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "t0 = time()\n",
    "tsne_lda = tsne_model.fit_transform(X_topics)\n",
    "print('sklearn took {} seconds'.format(time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.plotting as bp\n",
    "from bokeh.plotting import save, show\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "n_top_words = 5 # number of keywords we show\n",
    "\n",
    "# 20 colors\n",
    "colormap = np.array([\n",
    "    \"#1f77b4\", \"#aec7e8\", \"#ff7f0e\", \"#ffbb78\", \"#2ca02c\",\n",
    "    \"#98df8a\", \"#d62728\", \"#ff9896\", \"#9467bd\", \"#c5b0d5\",\n",
    "    \"#8c564b\", \"#c49c94\", \"#e377c2\", \"#f7b6d2\", \"#7f7f7f\",\n",
    "    \"#c7c7c7\", \"#bcbd22\", \"#dbdb8d\", \"#17becf\", \"#9edae5\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"3a677e3d-546f-42cc-b1c9-c9baa1c9e6bf\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lda_keys = []\n",
    "for i in range(X_topics.shape[0]):\n",
    "    _lda_keys +=  X_topics[i].argmax(),\n",
    "    \n",
    "topic_summaries = []\n",
    "topic_word = lda_model.topic_word_  # all topic words\n",
    "vocab = cvectorizer.get_feature_names()\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words + 1):-1] # get!\n",
    "    topic_summaries.append(' '.join(topic_words)) # append!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"0e9e0e3a-fdbb-4443-a287-701fb17251ae\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {},
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "b428407a-a361-4e9d-9ed5-78bac88dfbf1"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = '20 newsgroups LDA viz'\n",
    "num_example = len(X_topics)\n",
    "\n",
    "plot_lda = bp.figure(plot_width=900, plot_height=700,\n",
    "                     title=title,\n",
    "                     tools=\"pan, wheel_zoom, box_zoom, reset, hover, previewsave\",\n",
    "                     x_axis_type=None, y_axis_type=None, min_border=1)\n",
    "\n",
    "data_dict = {'content': news_snippets,\n",
    "             'topic_key': topics, \n",
    "             'x': tsne_lda[:, 0], \n",
    "             'y': tsne_lda[:, 1],\n",
    "             'color': colormap[labels][:num_example]}\n",
    "\n",
    "mySource = bp.ColumnDataSource(data_dict)\n",
    "\n",
    "plot_lda.circle(x='x', y='y', color='color', source=mySource)\n",
    "\n",
    "# Select the centroid of each LDA cluster as the coordinates to plot crucial words\n",
    "lda_labels = np.array(_lda_keys)\n",
    "topic_coord = np.zeros((X_topics.shape[1], 2))\n",
    "for i in range(X_topics.shape[1]):\n",
    "    mask = np.argwhere(lda_labels == i).flatten()\n",
    "    topic_coord[i] = np.average(tsne_lda[mask], axis=0)\n",
    "    \n",
    "# plot crucial words\n",
    "for i in range(X_topics.shape[1]):\n",
    "      plot_lda.text(topic_coord[i, 0], topic_coord[i, 1], [topic_summaries[i]], text_font_size='10px')\n",
    "\n",
    "# hover tools\n",
    "hover = plot_lda.select(dict(type=HoverTool))\n",
    "hover.tooltips = {\"content\": \"@content - topic: @topic_key\"}\n",
    "\n",
    "# save the plot\n",
    "#save(plot_lda, '{}.html'.format(title))\n",
    "show(plot_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['armenian turkish israel israeli jews',\n",
       " 'space nasa launch satellite data',\n",
       " 'information send list mail anonymous',\n",
       " 'president government people new american',\n",
       " 'hockey team game new nhl',\n",
       " 'god jesus bible christian church',\n",
       " 'time like think probably just',\n",
       " 'file entry use line program',\n",
       " 'people think does believe just',\n",
       " 'medical use health patients water',\n",
       " 'key encryption use chip government',\n",
       " 'use window db windows image',\n",
       " 'drive disk hard scsi dos',\n",
       " 'university information research new center',\n",
       " 'gun right law state people',\n",
       " 'car like new used bike',\n",
       " 'use card does know like',\n",
       " 'just like know think going',\n",
       " 'good year team game think',\n",
       " 'said went came took started']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_summaries # Notice that the topic summaries don't have a direct mapping to each label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
