{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle \n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn import manifold\n",
    "from sklearn.manifold.t_sne import trustworthiness\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.SimpleConvNet import SimpleConvNet\n",
    "from core.GraphConvNet2 import GraphConvNet2\n",
    "from core.DataEmbeddingGraph import DataEmbeddingGraph\n",
    "from util.plot_embedding import plot_embedding, plot_embedding_subplot\n",
    "from util.mnist_data_loader import get_train_set, get_test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda not available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('cuda available')\n",
    "    device = 'gpu'\n",
    "    dtypeFloat = torch.cuda.FloatTensor\n",
    "    dtypeLong = torch.cuda.LongTensor\n",
    "else:\n",
    "    print('cuda not available')\n",
    "    device = 'cpu'\n",
    "    dtypeFloat = torch.FloatTensor\n",
    "    dtypeLong = torch.LongTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_parameters = {}\n",
    "task_parameters['reduction_method'] = 'spectral'\n",
    "task_parameters['n_components'] = 2\n",
    "\n",
    "net_parameters = {}\n",
    "net_parameters['n_components'] = task_parameters['n_components']\n",
    "net_parameters['D'] = 784 # input dimension\n",
    "net_parameters['H'] = 50 # number of hidden units\n",
    "net_parameters['L'] = 10 # number of hidden layers\n",
    "net_parameters['n_channels'] = 1\n",
    "net_parameters['n_units_1'] = net_parameters['n_units_2'] = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/set_100_mnist_spectral_size_200_500.pkl'\n",
    "with open(filename, 'rb') as f:\n",
    "    [all_test_data] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "def l2_norm(v):\n",
    "    return np.sqrt(np.sum(np.square(v), axis=1, dtype=np.float64))\n",
    "\n",
    "def pairwise_loss_function_1(y_true, y_pred, W):\n",
    "    pairwise_loss_1 = mean_squared_error(y_true[W.row,:], y_true[W.col,:])\n",
    "    pairwise_loss_2 = mean_squared_error(y_pred[W.row,:], y_pred[W.col,:])\n",
    "    return np.square(pairwise_loss_1 - pairwise_loss_2)\n",
    "\n",
    "def pairwise_loss_function_2(y_true, y_pred, W):\n",
    "    pairwise_loss_1 = l2_norm(y_true[W.row,:] - y_true[W.col,:])\n",
    "    pairwise_loss_2 = l2_norm(y_pred[W.row,:] - y_pred[W.col,:])\n",
    "    return np.average(np.square(pairwise_loss_1 - pairwise_loss_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_net(net, all_test_data):\n",
    "    n_test = len(all_test_data)\n",
    "    similarity_tracker = np.zeros((n_test, ))\n",
    "    trust_tracker = np.zeros((n_test, ))\n",
    "    one_nn_tracker = np.zeros((n_test, ))\n",
    "    time_tracker = np.zeros((n_test, ))\n",
    "    \n",
    "    for i in range(n_test):\n",
    "        G = all_test_data[i]\n",
    "        time_start = timer()\n",
    "        y_pred = net.forward(G).detach().numpy()\n",
    "        time_end = timer()\n",
    "        time_tracker[i] = time_end - time_start\n",
    "        \n",
    "        similarity_tracker[i] =  pairwise_loss_function_2(G.target, y_pred, G.adj_matrix)\n",
    "        X = G.data.view(G.data.shape[0], -1).numpy()\n",
    "        trust_tracker[i] = trustworthiness(X, y_pred, n_neighbors=5)\n",
    "        one_nn_tracker[i] = one_nearest_neighbours_generalisation_error(y_pred, G.labels.numpy())\n",
    "    return similarity_tracker, trust_tracker, one_nn_tracker, time_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph net\n",
    "net = GraphConvNet2(net_parameters)\n",
    "root = 'results/mnist_spectral1/'\n",
    "filename = root + 'graph_net5.pkl'\n",
    "checkpoint = torch.load(filename, map_location=device)\n",
    "net.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = all_test_data[2]\n",
    "y_pred = net.forward(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012579493418748878\n"
     ]
    }
   ],
   "source": [
    "loss = pairwise_loss_function_2(y_pred.detach().numpy(), G.target, G.adj_matrix)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = Variable(torch.FloatTensor(G.target).type(dtypeFloat), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_pairwise_loss(y, y_target, W):\n",
    "    distances_1 = y_target[W.row,:] - y_target[W.col,:]\n",
    "    distances_2 = y[W.row,:] - y[W.col,:]\n",
    "    loss = torch.mean(torch.pow(distances_1.norm(dim=1) - distances_2.norm(dim=1), 2))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0126, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "loss = torch_pairwise_loss(y_pred, y_true, G.adj_matrix)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
